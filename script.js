import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2/dist/transformers.min.js';

// Configure Transformers.js environment
env.allowRemoteModels = true;
env.allowLocalModels = false;

class SpeechToTextApp {
    constructor() {
        this.pipe = null;
        this.mediaRecorder = null;
        this.audioChunks = [];
        this.isRecording = false;
        this.isModelLoaded = false;
        this.currentModelName = 'Xenova/whisper-small'; // Default to multilingual small model (better than base)
        
        // Timing tracking
        this.recordingStartTime = null;
        this.recordingDuration = null;
        this.processingStartTime = null;
        this.processingDuration = null;
        
        // Replay functionality
        this.lastRecordedBlob = null;
        this.lastProcessedAudioData = null;
        this.modelCache = new Map(); // Cache loaded models
        this.resultCache = new Map(); // Cache processing results per recording per model
        this.currentRecordingId = null; // Unique ID for current recording session
        this.availableModels = ['Xenova/whisper-tiny', 'Xenova/whisper-base', 'Xenova/whisper-small'];
        
        // Turkish test texts
        this.turkishTexts = [
            "Yapay zeka teknolojileri gÃ¼nÃ¼mÃ¼zde hÄ±zla geliÅŸiyor. Makine Ã¶ÄŸrenmesi algoritmalarÄ± sayesinde bilgisayarlar artÄ±k insan benzeri gÃ¶revleri yerine getirebiliyor. Bu geliÅŸmeler tÄ±ptan eÄŸitime kadar birÃ§ok alanda devrim yaratÄ±yor.",
            "DoÄŸa korunmasÄ± tÃ¼m insanlÄ±ÄŸÄ±n sorumluluÄŸudur. OrmanlarÄ± korumak, temiz hava solumak ve gelecek nesillere yaÅŸanabilir bir dÃ¼nya bÄ±rakmak iÃ§in bugÃ¼nden harekete geÃ§meliyiz. KÃ¼Ã§Ã¼k adÄ±mlar bÃ¼yÃ¼k deÄŸiÅŸimlere yol aÃ§ar.",
            "TÃ¼rk sanatÄ± binlerce yÄ±llÄ±k zengin bir geÃ§miÅŸe sahiptir. Geleneksel el sanatlarÄ±ndan modern resme, mÃ¼zikten edebiyata kadar uzanan bu kÃ¼ltÃ¼rel miras dÃ¼nyaca takdir edilir. Sanat insanlÄ±ÄŸÄ±n ortak dilidir.",
            "DÃ¼zenli spor yapmak hem fiziksel hem de ruhsal saÄŸlÄ±k iÃ§in Ã§ok Ã¶nemlidir. GÃ¼nde yarÄ±m saat yÃ¼rÃ¼yÃ¼ÅŸ bile vÃ¼cudumuzda olumlu deÄŸiÅŸiklikler yaratÄ±r. SaÄŸlÄ±klÄ± yaÅŸam alÄ±ÅŸkanlÄ±klarÄ± uzun vadede bÃ¼yÃ¼k farklar yaratÄ±r.",
            "EÄŸitim hayatÄ±n temel taÅŸÄ±dÄ±r. Ã–ÄŸrenme sÃ¼reci doÄŸumla baÅŸlar ve Ã¶lÃ¼mle son bulur. Her yaÅŸta yeni bilgiler edinmek ve kendimizi geliÅŸtirmek mÃ¼mkÃ¼ndÃ¼r. Merak ve Ã¶ÄŸrenme isteÄŸi en deÄŸerli hazinelerimizdir.",
            "TÃ¼rk mutfaÄŸÄ± dÃ¼nyada en zengin lezzetlerden birine sahiptir. Kebaptan baklava'ya, Ã§orbadan meze'ye kadar uzanan bu Ã§eÅŸitlilik damak tadÄ±mÄ±zÄ± ÅŸÄ±martÄ±r. Yemek kÃ¼ltÃ¼rÃ¼ toplumlarÄ±n kimliÄŸini yansÄ±tan Ã¶nemli bir unsurdur.",
            "Seyahat etmek ufkumuzu geniÅŸletir ve farklÄ± kÃ¼ltÃ¼rleri tanÄ±mamÄ±zÄ± saÄŸlar. Her yeni ÅŸehir, her yeni Ã¼lke bize farklÄ± perspektifler sunar. Gezi anÄ±larÄ± yaÅŸamÄ±mÄ±zÄ±n en deÄŸerli hatÄ±ralarÄ±dÄ±r.",
            "MÃ¼zik evrensel bir dildir. FarklÄ± kÃ¼ltÃ¼rlerden insanlarÄ± bir araya getirir ve duygularÄ±mÄ±zÄ± en gÃ¼zel ÅŸekilde ifade eder. Dans ise bedenin mÃ¼zikle buluÅŸtuÄŸu bÃ¼yÃ¼lÃ¼ bir sanattÄ±r.",
            "Bilimsel araÅŸtÄ±rmalar insanlÄ±ÄŸÄ±n ilerlemesinin temelini oluÅŸturur. Her yeni keÅŸif, her yeni buluÅŸ dÃ¼nyamÄ±zÄ± daha iyi anlamamÄ±za yardÄ±mcÄ± olur. Bilim meraktan doÄŸar ve sabÄ±rla bÃ¼yÃ¼r.",
            "TÃ¼rk tarihi ve medeniyeti dÃ¼nya tarihinde Ã¶nemli bir yere sahiptir. Anadolu topraklarÄ± binlerce yÄ±ldÄ±r farklÄ± kÃ¼ltÃ¼rlere ev sahipliÄŸi yapmÄ±ÅŸtÄ±r. Bu zengin miras gÃ¼nÃ¼mÃ¼ze kadar ulaÅŸan deÄŸerli bir hazinedir.",
            "Aile baÄŸlarÄ± hayatÄ±mÄ±zdaki en gÃ¼Ã§lÃ¼ destektir. Sevgi, saygÄ± ve anlayÄ±ÅŸla Ã¶rÃ¼lÃ¼ aile iliÅŸkileri mutluluÄŸumuzun temelidir. Dostluklar ise yaÅŸamÄ±mÄ±zÄ± renklendiren gÃ¼zel baÄŸlardÄ±r.",
            "Ä°ÅŸ hayatÄ±nda baÅŸarÄ± iÃ§in azim, sabÄ±r ve sÃ¼rekli Ã¶ÄŸrenme gereklidir. Kariyerimizi planlarken hem kiÅŸisel hedeflerimizi hem de toplumsal fayda saÄŸlayacak alanlarÄ± gÃ¶z Ã¶nÃ¼nde bulundurmalÄ±yÄ±z.",
            "Hobiler hayatÄ±mÄ±za anlam katar ve stresimizi azaltÄ±r. Ä°ster kitap okumak, ister bahÃ§Ä±vanlÄ±k yapmak olsun, sevdiÄŸimiz aktiviteler ruhumuzu besler. BoÅŸ zamanlarÄ±mÄ±zÄ± deÄŸerlendirmek Ã¶nemli bir yaÅŸam becerisidir.",
            "Kitaplar bilginin ve hayal gÃ¼cÃ¼nÃ¼n kapÄ±larÄ±nÄ± aÃ§ar. Okumak kelime daÄŸarcÄ±ÄŸÄ±mÄ±zÄ± geliÅŸtirir, empati yetimizi artÄ±rÄ±r ve farklÄ± dÃ¼nyalarÄ± keÅŸfetmemizi saÄŸlar. Edebiyat insanlÄ±k deneyiminin en gÃ¼zel yansÄ±malarÄ±ndan biridir.",
            "Mevsimler doÄŸanÄ±n bÃ¼yÃ¼lÃ¼ dÃ¶ngÃ¼sÃ¼nÃ¼ gÃ¶sterir. Ä°lkbaharÄ±n tazeliÄŸi, yazÄ±n sÄ±caklÄ±ÄŸÄ±, sonbaharÄ±n renkleri ve kÄ±ÅŸÄ±n sakinliÄŸi, her biri kendine Ã¶zgÃ¼ gÃ¼zellikler sunar. Hava durumu gÃ¼nlÃ¼k hayatÄ±mÄ±zÄ± etkileyen Ã¶nemli bir faktÃ¶rdÃ¼r.",
            "Åžehir hayatÄ±nÄ±n dinamizmi ve kÄ±rsal yaÅŸamÄ±n huzuru arasÄ±nda denge kurmak modern insanÄ±n arayÄ±ÅŸÄ±dÄ±r. BÃ¼yÃ¼k ÅŸehirler fÄ±rsatlar sunar ancak doÄŸayla baÄŸÄ±mÄ±zÄ± koparmamak da Ã¶nemlidir.",
            "UlaÅŸÄ±m teknolojileri sÃ¼rekli geliÅŸiyor. Toplu taÅŸÄ±ma sistemleri ÅŸehirlerin nefes almasÄ±nÄ± saÄŸlar. Trafik sorunlarÄ± ise Ã§Ã¶zÃ¼m bekleyen Ã¶nemli kentsel problemlerdir. SÃ¼rdÃ¼rÃ¼lebilir ulaÅŸÄ±m geleceÄŸin anahtarÄ±dÄ±r.",
            "BilinÃ§li tÃ¼ketim hem Ã§evreyi korur hem de ekonomik olmamÄ±zÄ± saÄŸlar. AlÄ±ÅŸveriÅŸ yaparken ihtiyaÃ§larÄ±mÄ±zÄ± gereksinimlerimizdÃ«n ayÄ±rmak Ã¶nemlidir. Kaliteli Ã¼rÃ¼nler uzun vadede daha ekonomik olabilir.",
            "Sosyal medya modern iletiÅŸimin vazgeÃ§ilmez parÃ§asÄ± haline geldi. Bu platformlar bilgi paylaÅŸÄ±mÄ±nÄ± kolaylaÅŸtÄ±rÄ±rken, dijital okuryazarlÄ±k ve eleÅŸtirel dÃ¼ÅŸÃ¼nme becerileri de giderek Ã¶nem kazanÄ±yor.",
            "RÃ¼yalar bilinÃ§altÄ±mÄ±zÄ±n gizemli mesajlarÄ±dÄ±r. Hayal kurmak ise yaratÄ±cÄ±lÄ±ÄŸÄ±mÄ±zÄ± besleyen ve hedeflerimizi belirlememize yardÄ±mcÄ± olan gÃ¼Ã§lÃ¼ bir araÃ§tÄ±r. Ä°nsan hayal gÃ¼cÃ¼ sÄ±nÄ±rsÄ±z bir potansiyele sahiptir."
        ];
        
        this.initializeElements();
        this.initializeModel();
    }
    
    initializeElements() {
        this.recordButton = document.getElementById('record-button');
        this.transcriptionText = document.getElementById('transcription-text');
        this.statusDot = document.querySelector('.status-dot');
        this.statusText = document.querySelector('.status-text');
        this.buttonText = document.querySelector('.button-text');
        this.modelSelect = document.getElementById('model-select');
        this.testTextSelect = document.getElementById('test-text-select');
        this.selectedTextDisplay = document.getElementById('selected-text');
        this.copyTextButton = document.getElementById('copy-text-button');
        
        // Replay section elements
        this.replaySection = document.getElementById('replay-section');
        this.replayButtons = document.querySelectorAll('.replay-button');

        // Restore saved model from localStorage if present and valid, otherwise use default
        try {
            const savedModel = localStorage.getItem('whisper_selected_model');
            if (savedModel) {
                const optionExists = Array.from(this.modelSelect.options).some(opt => opt.value === savedModel);
                if (optionExists) {
                    this.currentModelName = savedModel;
                }
            }
        } catch (e) {
            // ignore storage errors (e.g., private mode)
            console.warn('localStorage not available:', e);
        }

        // Make selected model in dropdown match current model
        this.modelSelect.value = this.currentModelName;
        
        this.recordButton.addEventListener('click', () => this.toggleRecording());
        this.modelSelect.addEventListener('change', () => this.onModelChange());
        this.testTextSelect.addEventListener('change', () => this.onTextSelection());
        this.copyTextButton.addEventListener('click', () => this.copySelectedText());
        
        // Add event listeners for replay buttons
        this.replayButtons.forEach(button => {
            button.addEventListener('click', (e) => this.replayWithModel(e.target.dataset.model));
        });
    }
    
    async initializeModel() {
        try {
            const modelName = this.currentModelName;
            const modelSize = modelName.split('-').pop(); // Extract size (tiny, base, small, etc.)
            
            this.updateStatus('loading', `Whisper ${modelSize} modeli yÃ¼kleniyor...`);
            this.buttonText.textContent = 'Model YÃ¼kleniyor...';
            this.recordButton.disabled = true;
            this.modelSelect.disabled = true;
            
            // Check if model is already cached
            if (this.modelCache.has(modelName)) {
                this.pipe = this.modelCache.get(modelName);
                console.log(`${modelName} loaded from cache`);
            } else {
                // Load the selected multilingual Whisper model
                this.pipe = await pipeline('automatic-speech-recognition', modelName);
                // Cache the loaded model
                this.modelCache.set(modelName, this.pipe);
                console.log(`${modelName} (multilingual) model loaded and cached`);
            }
            
            this.isModelLoaded = true;
            this.updateStatus('ready', 'Kayda hazÄ±r');
            this.recordButton.disabled = false;
            this.modelSelect.disabled = false;
            this.buttonText.textContent = 'KaydÄ± BaÅŸlat';
            
        } catch (error) {
            console.error('Error loading model:', error);
            this.updateStatus('error', 'Model yÃ¼klenirken hata oluÅŸtu');
            this.buttonText.textContent = 'Model YÃ¼klenemedi';
            this.modelSelect.disabled = false;
        }
    }
    
    async onModelChange() {
        const newModelName = this.modelSelect.value;
        if (newModelName !== this.currentModelName) {
            this.currentModelName = newModelName;
            // Persist the user's model choice so it survives reloads
            try {
                localStorage.setItem('whisper_selected_model', newModelName);
            } catch (e) {
                console.warn('Could not persist model selection to localStorage:', e);
            }
            this.isModelLoaded = false;
            this.pipe = null;
            await this.initializeModel();
        }
    }
    
    updateStatus(type, message) {
        this.statusText.textContent = message;
        this.statusDot.className = `status-dot ${type}`;
    }
    
    async toggleRecording() {
        if (!this.isModelLoaded) {
            alert('Model hÃ¢lÃ¢ yÃ¼kleniyor. LÃ¼tfen bekleyin...');
            return;
        }
        
        if (this.isRecording) {
            this.stopRecording();
        } else {
            await this.startRecording();
        }
    }
    
    async startRecording() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    sampleRate: 16000,
                    channelCount: 1,
                    echoCancellation: true,
                    noiseSuppression: true
                } 
            });
            
            this.audioChunks = [];
            this.mediaRecorder = new MediaRecorder(stream, {
                mimeType: 'audio/webm;codecs=opus'
            });
            
            this.mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    this.audioChunks.push(event.data);
                }
            };
            
            this.mediaRecorder.onstop = () => {
                this.processAudio();
                stream.getTracks().forEach(track => track.stop());
            };
            
            this.mediaRecorder.start();
            this.isRecording = true;
            this.recordingStartTime = Date.now(); // Start timing
            
            // Clear previous replay section when starting new recording
            if (this.replaySection) {
                this.replaySection.style.display = 'none';
            }
            
            this.recordButton.classList.add('recording');
            this.buttonText.textContent = 'KaydÄ± Durdur';
            this.updateStatus('recording', 'Kaydediliyor... Durdurmak iÃ§in tÄ±klayÄ±n');
            
        } catch (error) {
            console.error('Error accessing microphone:', error);
            alert('Mikrofona eriÅŸilirken hata oluÅŸtu. LÃ¼tfen mikrofon izinlerini verdiÄŸinizden emin olun.');
        }
    }
    
    stopRecording() {
        if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
            this.mediaRecorder.stop();
            this.isRecording = false;
            this.recordingDuration = Date.now() - this.recordingStartTime; // Calculate duration
            
            this.recordButton.classList.remove('recording');
            this.buttonText.textContent = 'Ä°ÅŸleniyor...';
            this.updateStatus('processing', 'Ses iÅŸleniyor...');
        }
    }
    
    async processAudio() {
        this.processingStartTime = Date.now(); // Start processing timer
        try {
            if (this.audioChunks.length === 0) {
                this.resetUI();
                return;
            }
            
            // Create audio blob
            const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm;codecs=opus' });
            
            // Store the recording for replay functionality
            this.lastRecordedBlob = audioBlob;
            
            // Generate unique recording ID and clear old results
            this.currentRecordingId = Date.now().toString();
            this.resultCache.clear();
            
            // Convert to ArrayBuffer
            const arrayBuffer = await audioBlob.arrayBuffer();
            
            // Create audio context to process the audio
            const audioContext = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: 16000
            });
            
            // Decode audio data
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            
            // Get audio data as Float32Array (Whisper expects mono audio at 16kHz)
            let audioData = audioBuffer.getChannelData(0);
            
            // Resample to 16kHz if necessary
            if (audioBuffer.sampleRate !== 16000) {
                audioData = this.resampleAudio(audioData, audioBuffer.sampleRate, 16000);
            }
            
            // Store processed audio data for replay
            this.lastProcessedAudioData = audioData;
            
            this.updateStatus('processing', 'KonuÅŸma metne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...');
            
            // Run inference with Turkish language preference
            const result = await this.pipe(audioData, {
                chunk_length_s: 30,
                stride_length_s: 5,
                language: 'turkish', // Specify Turkish language for better recognition
                task: 'transcribe'
            });
            
            // Display result
            const transcription = result.text.trim();
            this.processingDuration = Date.now() - this.processingStartTime; // Calculate processing duration
            
            // Cache the result for current model
            this.resultCache.set(this.currentModelName, {
                transcription: transcription,
                processingDuration: this.processingDuration,
                timestamp: Date.now()
            });
            
            if (transcription) {
                this.transcriptionText.value = transcription;
                this.updateStatus('ready', 'Transkripsiyon tamamlandÄ±');
                this.displayTimingInfo();
                this.displayDiffComparison(transcription);
                this.showReplaySection(); // Show replay buttons after successful transcription
            } else {
                this.transcriptionText.value = 'Ses algÄ±lanamadÄ±. LÃ¼tfen daha net konuÅŸmayÄ± deneyin.';
                this.updateStatus('ready', 'Ses algÄ±lanamadÄ±');
                this.displayTimingInfo();
                this.showReplaySection(); // Show replay buttons even if transcription failed
            }
            
        } catch (error) {
            console.error('Error processing audio:', error);
            this.transcriptionText.value = 'Ses iÅŸlenirken hata oluÅŸtu. LÃ¼tfen tekrar deneyin.';
            this.updateStatus('ready', 'Hata oluÅŸtu');
        } finally {
            this.resetUI();
        }
    }
    
    resampleAudio(audioData, originalSampleRate, targetSampleRate) {
        if (originalSampleRate === targetSampleRate) {
            return audioData;
        }
        
        const ratio = originalSampleRate / targetSampleRate;
        const newLength = Math.round(audioData.length / ratio);
        const resampledData = new Float32Array(newLength);
        
        for (let i = 0; i < newLength; i++) {
            const originalIndex = i * ratio;
            const index = Math.floor(originalIndex);
            const fraction = originalIndex - index;
            
            if (index + 1 < audioData.length) {
                resampledData[i] = audioData[index] * (1 - fraction) + audioData[index + 1] * fraction;
            } else {
                resampledData[i] = audioData[index];
            }
        }
        
        return resampledData;
    }
    
    resetUI() {
    this.buttonText.textContent = 'KaydÄ± BaÅŸlat';
        this.recordButton.classList.remove('recording');
        this.recordButton.disabled = false;
        
        setTimeout(() => {
            this.updateStatus('ready', 'Kayda hazÄ±r');
        }, 2000);
    }
    
    displayTimingInfo() {
        const timingInfoEl = document.getElementById('timing-info');
        if (timingInfoEl && this.recordingDuration && this.processingDuration) {
            const recordingSeconds = (this.recordingDuration / 1000).toFixed(1);
            const processingSeconds = (this.processingDuration / 1000).toFixed(1);
            timingInfoEl.innerHTML = `
                <span class="timing-item">ðŸ“¼ KayÄ±t: ${recordingSeconds}s</span>
                <span class="timing-item">âš¡ Ä°ÅŸleme: ${processingSeconds}s</span>
            `;
            timingInfoEl.style.display = 'flex';
        }
    }
    
    displayDiffComparison(transcription) {
        const selectedTextIndex = this.testTextSelect.value;
        if (selectedTextIndex && this.turkishTexts[selectedTextIndex]) {
            const originalText = this.turkishTexts[selectedTextIndex];
            const diffContainer = document.getElementById('diff-comparison');
            if (diffContainer) {
                const diffHtml = this.generateDiffHtml(originalText, transcription);
                const accuracyPercentage = this.calculateAccuracyPercentage(originalText, transcription);
                diffContainer.innerHTML = `
                    <div class="diff-header">
                        Metin KarÅŸÄ±laÅŸtÄ±rmasÄ±
                        <span class="accuracy-percentage">%${accuracyPercentage} doÄŸruluk</span>
                    </div>
                    <div class="diff-content">${diffHtml}</div>
                `;
                diffContainer.style.display = 'block';
            }
        }
    }
    
    generateDiffHtml(original, transcribed) {
        // Normalize text: remove punctuation and convert to Turkish lowercase
        const toTurkishLowerCase = (text) => text.replace(/Ä°/g, 'i').replace(/I/g, 'Ä±').toLowerCase();
        const normalizePunctuation = (text) => toTurkishLowerCase(text).replace(/[.,;:!?'"()[\]{}\-â€“â€”]/g, '').replace(/\s+/g, ' ').trim();
        
        const originalWords = normalizePunctuation(original).split(/\s+/);
        const transcribedWords = normalizePunctuation(transcribed).split(/\s+/);
        
        // Create a simple diff using word matching
        let result = '';
        let originalIndex = 0;
        let transcribedIndex = 0;
        
        while (originalIndex < originalWords.length || transcribedIndex < transcribedWords.length) {
            if (originalIndex >= originalWords.length) {
                // Only transcribed words left (additions)
                result += `<span class="diff-added">+${transcribedWords[transcribedIndex]}</span> `;
                transcribedIndex++;
            } else if (transcribedIndex >= transcribedWords.length) {
                // Only original words left (deletions)
                result += `<span class="diff-removed">-${originalWords[originalIndex]}</span> `;
                originalIndex++;
            } else if (originalWords[originalIndex] === transcribedWords[transcribedIndex]) {
                // Words match
                result += `<span class="diff-unchanged">${originalWords[originalIndex]}</span> `;
                originalIndex++;
                transcribedIndex++;
            } else {
                // Words don't match - try to find next match
                const nextMatch = this.findNextMatch(originalWords, transcribedWords, originalIndex, transcribedIndex);
                
                if (nextMatch.originalSkip > 0) {
                    // Words were deleted from original
                    for (let i = 0; i < nextMatch.originalSkip; i++) {
                        result += `<span class="diff-removed">-${originalWords[originalIndex + i]}</span> `;
                    }
                    originalIndex += nextMatch.originalSkip;
                }
                
                if (nextMatch.transcribedSkip > 0) {
                    // Words were added to transcription
                    for (let i = 0; i < nextMatch.transcribedSkip; i++) {
                        result += `<span class="diff-added">+${transcribedWords[transcribedIndex + i]}</span> `;
                    }
                    transcribedIndex += nextMatch.transcribedSkip;
                }
            }
        }
        
        return result.trim();
    }
    
    findNextMatch(originalWords, transcribedWords, originalStart, transcribedStart) {
        // Simple heuristic: look ahead up to 3 words to find a match
        const maxLookAhead = 3;
        
        for (let origSkip = 0; origSkip <= maxLookAhead && originalStart + origSkip < originalWords.length; origSkip++) {
            for (let transSkip = 0; transSkip <= maxLookAhead && transcribedStart + transSkip < transcribedWords.length; transSkip++) {
                if (originalWords[originalStart + origSkip] === transcribedWords[transcribedStart + transSkip]) {
                    return { originalSkip: origSkip, transcribedSkip: transSkip };
                }
            }
        }
        
        // No match found, assume single word difference
        return { originalSkip: 1, transcribedSkip: 1 };
    }
    
    calculateAccuracyPercentage(original, transcribed) {
        // Normalize both texts for comparison (Turkish lowercase, remove punctuation and extra spaces)
        const toTurkishLowerCase = (text) => text.replace(/Ä°/g, 'i').replace(/I/g, 'Ä±').toLowerCase();
        const normalizeText = (text) => toTurkishLowerCase(text).replace(/[.,;:!?'"()[\]{}\-â€“â€”]/g, '').replace(/\s+/g, ' ').trim();
        const originalNormalized = normalizeText(original);
        const transcribedNormalized = normalizeText(transcribed);
        
        // Use Levenshtein distance algorithm for character-based similarity
        const distance = this.levenshteinDistance(originalNormalized, transcribedNormalized);
        const maxLength = Math.max(originalNormalized.length, transcribedNormalized.length);
        
        if (maxLength === 0) return 100;
        
        const accuracy = ((maxLength - distance) / maxLength) * 100;
        return Math.round(accuracy);
    }
    
    levenshteinDistance(str1, str2) {
        const matrix = [];
        
        // Create matrix
        for (let i = 0; i <= str2.length; i++) {
            matrix[i] = [i];
        }
        for (let j = 0; j <= str1.length; j++) {
            matrix[0][j] = j;
        }
        
        // Fill matrix
        for (let i = 1; i <= str2.length; i++) {
            for (let j = 1; j <= str1.length; j++) {
                if (str2.charAt(i - 1) === str1.charAt(j - 1)) {
                    matrix[i][j] = matrix[i - 1][j - 1];
                } else {
                    matrix[i][j] = Math.min(
                        matrix[i - 1][j - 1] + 1, // substitution
                        matrix[i][j - 1] + 1,     // insertion
                        matrix[i - 1][j] + 1      // deletion
                    );
                }
            }
        }
        
        return matrix[str2.length][str1.length];
    }
    
    onTextSelection() {
        const selectedIndex = this.testTextSelect.value;
        if (selectedIndex === '') {
            this.selectedTextDisplay.innerHTML = '<p class="placeholder-text">YukarÄ±dan bir metin seÃ§in ve yÃ¼ksek sesle okuyun.</p>';
            this.copyTextButton.style.display = 'none';
        } else {
            const selectedText = this.turkishTexts[parseInt(selectedIndex)];
            this.selectedTextDisplay.innerHTML = `<p>${selectedText}</p>`;
            this.copyTextButton.style.display = 'block';
        }
    }
    
    copySelectedText() {
        const textElement = this.selectedTextDisplay.querySelector('p:not(.placeholder-text)');
        if (textElement) {
            navigator.clipboard.writeText(textElement.textContent).then(() => {
                const originalText = this.copyTextButton.textContent;
                this.copyTextButton.textContent = 'KopyalandÄ±!';
                this.copyTextButton.style.background = '#00a085';
                
                setTimeout(() => {
                    this.copyTextButton.textContent = originalText;
                    this.copyTextButton.style.background = '#00b894';
                }, 1500);
            }).catch(err => {
                console.error('Text copying failed:', err);
                alert('Metin kopyalanamadÄ±. LÃ¼tfen manuel olarak seÃ§in.');
            });
        }
    }
    
    showReplaySection() {
        if (this.lastProcessedAudioData && this.replaySection) {
            // Update button states - show cached results indicators
            this.replayButtons.forEach(button => {
                const buttonModel = button.dataset.model;
                const modelSize = buttonModel.split('-').pop().toUpperCase();
                
                if (this.resultCache.has(buttonModel)) {
                    const cached = this.resultCache.get(buttonModel);
                    const duration = (cached.processingDuration / 1000).toFixed(1);
                    button.textContent = `${modelSize} (${duration}s) âœ“`;
                    button.className = 'replay-button cached';
                } else {
                    button.textContent = `${modelSize} ile Test Et`;
                    button.className = 'replay-button';
                }
                button.disabled = false;
            });
            this.replaySection.style.display = 'block';
        }
    }
    
    async replayWithModel(modelName) {
        if (!this.lastProcessedAudioData) {
            alert('Tekrar oynatÄ±lacak kayÄ±t bulunamadÄ±.');
            return;
        }
        
        const button = document.querySelector(`[data-model="${modelName}"]`);
        const modelSize = modelName.split('-').pop().toUpperCase();
        const originalText = button.textContent;
        
        // Check if we have cached results for this model and recording
        if (this.resultCache.has(modelName)) {
            const cached = this.resultCache.get(modelName);
            // Display cached result
            const resultText = `[${modelSize} Model - ${(cached.processingDuration/1000).toFixed(1)}s - Ã–nbellekten]\n${cached.transcription}`;
            this.transcriptionText.value = resultText;
            this.displayDiffComparison(cached.transcription);
            
            // Update timing info to show this model's processing time
            const timingInfoEl = document.getElementById('timing-info');
            if (timingInfoEl && this.recordingDuration) {
                const recordingSeconds = (this.recordingDuration / 1000).toFixed(1);
                const processingSeconds = (cached.processingDuration / 1000).toFixed(1);
                timingInfoEl.innerHTML = `
                    <span class="timing-item">ðŸ“¼ KayÄ±t: ${recordingSeconds}s</span>
                    <span class="timing-item">âš¡ Ä°ÅŸleme (${modelSize}): ${processingSeconds}s</span>
                `;
            }
            return;
        }
        
        // Need to process with this model
        try {
            button.disabled = true;
            
            // Load model if not cached
            let pipeline_instance;
            if (this.modelCache.has(modelName)) {
                pipeline_instance = this.modelCache.get(modelName);
                button.textContent = `${modelSize} Ä°ÅŸleniyor...`;
                button.className = 'replay-button processing';
                // Force DOM update
                await new Promise(resolve => requestAnimationFrame(resolve));
            } else {
                button.textContent = `${modelSize} Ä°ndiriliyor...`;
                button.className = 'replay-button downloading';
                // Force DOM update
                await new Promise(resolve => requestAnimationFrame(resolve));
                
                pipeline_instance = await pipeline('automatic-speech-recognition', modelName);
                this.modelCache.set(modelName, pipeline_instance);
                
                button.textContent = `${modelSize} Ä°ÅŸleniyor...`;
                button.className = 'replay-button processing';
                // Force DOM update
                await new Promise(resolve => requestAnimationFrame(resolve));
            }
            
            const startTime = Date.now();
            
            // Run inference with the selected model
            const result = await pipeline_instance(this.lastProcessedAudioData, {
                chunk_length_s: 30,
                stride_length_s: 5,
                language: 'turkish',
                task: 'transcribe'
            });
            
            const processingTime = Date.now() - startTime;
            const transcription = result.text.trim();
            
            // Cache the result
            this.resultCache.set(modelName, {
                transcription: transcription,
                processingDuration: processingTime,
                timestamp: Date.now()
            });
            
            // Display result in transcription area with model info
            const resultText = `[${modelSize} Model - ${(processingTime/1000).toFixed(1)}s]\n${transcription}`;
            this.transcriptionText.value = resultText;
            
            // Update diff comparison
            this.displayDiffComparison(transcription);
            
            // Update timing info to show this model's processing time
            const timingInfoEl = document.getElementById('timing-info');
            if (timingInfoEl && this.recordingDuration) {
                const recordingSeconds = (this.recordingDuration / 1000).toFixed(1);
                const processingSeconds = (processingTime / 1000).toFixed(1);
                timingInfoEl.innerHTML = `
                    <span class="timing-item">ðŸ“¼ KayÄ±t: ${recordingSeconds}s</span>
                    <span class="timing-item">âš¡ Ä°ÅŸleme (${modelSize}): ${processingSeconds}s</span>
                `;
            }
            
            // Update the replay section to reflect new cached result
            this.showReplaySection();
            
        } catch (error) {
            console.error(`Error with ${modelName}:`, error);
            alert(`${modelName} modelinde hata oluÅŸtu.`);
            // Restore button to original state on error
            const modelSize = modelName.split('-').pop().toUpperCase();
            button.textContent = `${modelSize} ile Test Et`;
            button.className = 'replay-button';
            button.disabled = false;
        }
    }
}

// Initialize the app when the page loads
document.addEventListener('DOMContentLoaded', () => {
    new SpeechToTextApp();
});

// Handle microphone permission
navigator.permissions.query({ name: 'microphone' }).then((result) => {
    if (result.state === 'denied') {
        console.warn('Microphone permission denied');
    }
});